# Яндекс Практикум. Инженер данных. 6 спринт. Проектная работа по аналитическим базам данных

## Выполнение проекта

### 1. Изучение технологий, которые используются для получения данных из источников

1. Для наполнения хранилища данными из разных источников используются технологии:

   - PostgreSQL: данные бонусной системы о пользователях, рангах и событиях
   - Mongo DB: данные из сисемы заказов о ресторанах, пользователях и заказах
   - API: данные о курьерах и доставках

### Очистка базы данных перед обновлением


2. Подготовка DDL-скриптов для создания слоёв и таблиц в хранилище:
3. 
Очистка базы данных от старых таблиц для подготовки к обновлению структуры данных.

1. Очистка слоёв DWH и STAGING от таблиц с помощью :
   - Таблицы хабов
   - Спутниковые таблицы
   - Связующие таблицы
   - Промежуточные таблицы первичной загрузки и обработки данных
   - Таблицы с приставкой _rej для отклоненных записей

Airflow

Скачивание файлов из файлового хранилища с помощью boto3

2. Создание подключений к БД в среде Airflow
   - PostgreSQL connection `PG_ORIGIN_BONUS_SYSTEM_CONNECTION` для забора данных из внешнего источника
     - host: `rc1a-1kn18k47wuzaks6h.mdb.yandexcloud.net`
     - port: `6432`
     - sslmode: `require`
     - dbname: `de-public`
     - user: `student`
     - password: `student1`

CTE

Ответ бизнесу



Импорт данных: Загрузите group_log.csv из корзины S3 sprint6 в промежуточную зону.
Настройка схемы базы данных: Создайте таблицы в Vertica для размещения структуры входящих данных.
Загрузка данных в Vertica: Реализуйте DAG в Airflow, который читает файл CSV и загружает его в таблицу group_log.
Создание таблицы связей: Добавьте в схему DWH таблицу связей для соединения данных пользователя и группы.
Сценарии миграции: Напишите SQL-скрипты для миграции данных из промежуточной зоны в таблицу связей, а затем в спутниковую таблицу, фиксирующую истории авторизаций.
Создание и заполнение спутников: Создайте спутниковую таблицу для хранения подробных журналов событий.
Подготовка CTE для бизнес-запросов: Реализуйте Common Table Expressions (CTE) для оптимального извлечения данных и ответа на бизнес-запросы о вовлеченности пользователей в группы.

Шаг 3: Создание таблиц в STAGING
Создайте структуру таблиц для первичного хранения данных перед их обработкой и переносом в DWH.

Таблица users для данных пользователей.
Таблица groups для данных о группах.
Таблица dialogs для данных о сообщениях и диалогах.
Шаг 4: Создание таблиц в DWH
Создайте таблицы в хранилище данных, которые будут использоваться для долгосрочного хранения и анализа данных.

Хабы:
h_users для пользовательских данных.
h_dialogs для данных о сообщениях.
h_groups для данных о группах.
Связи:
l_user_message для связей между пользователями и сообщениями.
l_admins для связей между администраторами и их группами.
l_groups_dialogs для связей между группами и диалогами.
Спутники:
s_admins, s_user_chatinfo, s_group_name, s_group_private_status, s_dialog_info, s_user_socdem для хранения дополнительных деталей об элементах в хабах.

Обзор проекта

Этот проект включает создание и развитие аналитической базы данных, предназначенной для помощи маркетологам в оптимизации рекламы в социальных сетях. Наша основная цель — определить сообщества с высокой конверсией, где значительная часть пользователей активно участвует в обсуждениях, что указывает на высокие показатели конверсии первых сообщений.

Бизнес-задача
Для привлечения новых пользователей маркетологи хотят разместить рекламу активных сообществ на сторонних сайтах. Наша задача — выявить такие группы, где большая часть участников активно участвует, что указывает на высокие показатели конверсии первого сообщения.

Описание данных

Мы работаем с файлом group_log.csv, который включает следующие колонки:

group_id: Уникальный идентификатор группы.
user_id: Уникальный идентификатор пользователя.
user_id_from: Указывает, был ли пользователь добавлен другим участником (непустое значение, если да).
event: Действие пользователя (create, add, leave).
datetime: Временная метка события.

Ожидаемые результаты

Анализируя данные в нашем DWH, мы стремимся предоставить маркетологам практические выводы о том, какие сообщества следует целить для рекламы на основе показателей конверсии. Это поможет проводить более эффективную рекламу в социальных сетях, увеличивая привлечение и вовлечение пользователей.

Дальнейшие шаги
Дальнейшее развитие может включать интеграцию данных в реальном времени для постоянного мониторинга активности сообществ и динамической корректировки маркетинговых стратегий на основе текущих тенденций и анализа поведения пользователей.

Используемые технологии

AWS S3 для хранения данных.
Apache Airflow для оркестровки.
HP Vertica для хранения данных.
SQL для манипуляции данными и выполнения запросов.

### Описание
Репозиторий предназначен для сдачи проекта 6-го српинта

### Как работать с репозиторием
1. В вашем GitHub-аккаунте автоматически создастся репозиторий `de-project-sprint-6` после того, как вы привяжете свой GitHub-аккаунт на Платформе.
2. Скопируйте репозиторий на свой локальный компьютер, в качестве пароля укажите ваш `Access Token` (получить нужно на странице [Personal Access Tokens](https://github.com/settings/tokens)):
	* `git clone https://github.com/{{ username }}/de-project-sprint-6.git`
3. Перейдите в директорию с проектом: 
	* `cd de-project-sprint-6`
4. Выполните проект и сохраните получившийся код в локальном репозитории:
	* `git add .`
	* `git commit -m 'my best commit'`
5. Обновите репозиторий в вашем GutHub-аккаунте:
	* `git push origin main`

### Структура репозитория
- `/src/dags`

### Как запустить контейнер
Запустите локально команду:
```
docker run \
-d \
-p 3000:3000 \
-p 3002:3002 \
-p 15432:5432 \
--mount src=airflow_sp5,target=/opt/airflow \
--mount src=lesson_sp5,target=/lessons \
--mount src=db_sp5,target=/var/lib/postgresql/data \
--name=de-sprint-5-server-local \
cr.yandex/crp1r8pht0n0gl25aug1/de-pg-cr-af:latest
```

После того как запустится контейнер, вам будут доступны:
- Airflow
	- `localhost:3000/airflow`
- БД
	- `jovyan:jovyan@localhost:15432/de`
