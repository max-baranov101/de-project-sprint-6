# Яндекс Практикум. Инженер данных. 6 спринт. Проектная работа по аналитическим базам данных

## Общее описание

- Репозиторий предназначен для сдачи проекта 6-го спринта по по аналитическим базам данных
- Этот проект включает создание и развитие аналитической базы данных Vertica, предназначенной для помощи маркетологам в оптимизации рекламы в социальных сетях.
- Основная цель проекта: расширить модель данных и развить БД Vertica для анализа активности пользователей в сообществах.
- Бизнес-задача: определить сообщества с высокой конверсией, где значительная часть пользователей активно участвует в обсуждениях, что указывает на высокие показатели конверсии первых сообщений. Это необходимо маркетологам для размещения рекламы активных сообществ на сторонних сайтах для привлечения новых пользователей.

## Изучение технологий, которые используются для получения данных из источников

- AWS S3: хранение исходных данных.
- Apache Airflow: оркестровка процесса загрузки данных.
- HP Vertica: хранилище данных для аналитики.
- SQL: манипуляция данными и выполнения запросов.
  
## Изучение данных

1. Источник данных для БД — S3.
2. Данные в S3 лежат в бакетах.
3. Креды для подключения к S3
   - AWS_ACCESS_KEY_ID = "YCAJEWXOyY8Bmyk2eJL-hlt2K"
   - AWS_SECRET_ACCESS_KEY = "YCPs52ajb2jNXxOUsL4-pFDL1HnV2BCPd928_ZoA"
4. Описание данных
   - `users.csv`: информация о пользователях
     - `id` — уникальный идентификатор пользователя
     - `сhat_name` — имя/название чата
     - `registration_dt` — дата регистрации пользователя
     - `country` — страна пользователя
     - `age` — возраст
   - `groups.csv`: информация о группах
     - `id` — идентификатор группы пользователей
     - `admin_id` — идентификатор администратора
     - `group_name` — название группы
     - `registration_dt` — дата регистрации группы
     - `is_private` — является ли группа приватной
   - `dialogs.csv`: информация о диалогах
     - `message_id` — это идентификатор сообщения
     - `datetime` — дата и время сообщения
     - `message_from` — идентификатор отправителя сообщения
     - `message_to` — идентификатор получателя
     - `message` — текст сообщения
   - `group_log.csv`: логи групп
     - `group_id` — уникальный идентификатор группы;
     - `user_id` - уникальный идентификатор пользователя.
     - `user_id_from` — поле для отметки о том, что пользователь не сам вступил в группу, а его добавил другой участник. Если пользователя пригласил в группу кто-то другой, поле будет непустым.
     - `event` - действие пользователя (`create`, `add`, `leave`).
     - `datetime` - временная метка события

## Выполнение проекта

### Подготовка DDL-скриптов

1. Очистка базы данных Vertica перед обновлением ([0_clear_db.sql](src/sql/0_clear_db.sql))
2. Создание таблиц STAGING ([1_ddl_stg.sql](src/sql/1_ddl_stg.sql))
3. Расширение STAGING согласно условиям данного проекта: создание таблицы `group_log` с учётом формата данных в скачанном файле `group_log.csv`.
4. Создание таблиц DWH ([3_ddl_dwh.sql](src/sql/3_ddl_dwh.sql))
5. Расширение DWH согласно условиям данного проекта:
   - Создание таблицы связи `l_user_group_activity` ([4_create_l_user_group_activity.sql](src/sql/4_create_l_user_group_activity.sql))
     - `hk_l_user_group_activity` — основной ключ типа `INT`
     - `hk_user_id` — внешний ключ типа `INT`, который связан с основным ключом хаба `h_users`
     - `hk_group_id` — внешний ключ типа `INT`, который связан с основным ключом хаба `h_groups`
     - `load_dt` — временная отметка типа `DATETIME` о том, когда были загружены данные
     - `load_src` — данные об источнике типа `VARCHAR(20)`
   - Создание таблицы сателлита `s_auth_history` ([5_create_s_auth_history.sql](src/sql/5_create_s_auth_history.sql))
     - `hk_l_user_group_activity` — внешний ключ к ранее созданной таблице связей типа `INT`
     - `user_id_from` — идентификатор типа `INT` того пользователя, который добавил в группу другого
     - `event` — событие пользователя в группе;
     - `event_dt` — дата и время, когда совершилось событие;
     - `load_dt` — временная отметка типа `DATETIME` о том, когда были загружены данные
     - `load_src` — данные об источнике типа `VARCHAR(20)`
6. Запуск DDL-скриптов один раз из файла [ddl_full.py](src/ddl_full.py)

### Сбор данных

### Наполнение данных
Если новый участник вступил в сообщество сам, это поле пустое. Задайте атрибуту user_id_from  и наполните его из исходных загруженных данных *__STAGING.group_log.
Очистка базы данных от старых таблиц для подготовки к обновлению структуры данных.

1. Очистка слоёв DWH и STAGING от таблиц с помощью :
   - Таблицы хабов
   - Спутниковые таблицы
   - Связующие таблицы
   - Промежуточные таблицы первичной загрузки и обработки данных
   - Таблицы с приставкой _rej для отклоненных записей

Airflow

Скачивание файлов из файлового хранилища с помощью boto3

2. Создание подключений к БД в среде Airflow
   - PostgreSQL connection `PG_ORIGIN_BONUS_SYSTEM_CONNECTION` для забора данных из внешнего источника
     - host: `rc1a-1kn18k47wuzaks6h.mdb.yandexcloud.net`
     - port: `6432`
     - sslmode: `require`
     - dbname: `de-public`
     - user: `student`
     - password: `student1`

CTE

### Ответ бизнесу

1. Подготовка комплексного SQL-запроса для ответа на вопрос бизнеса для десяти самых старых групп
   - Хэш-ключ группы `hk_group_id`
   - Количество новых пользователей `cnt_added_users` в таких группах
   - Количество пользователей `cnt_users_in_group_with_messages` в каждой такой группе, которые написали хотя бы одно сообщение
   - Доля пользователей `group_conversion` в каждой такой группе, которые начали общаться
   - Все метрики должны быть отсортированы по убыванию `group_conversion`
1. Запуск SQL-запроса из файла [ddl_full.py](src/ddl_full.py)
3. Результаты запроса


Импорт данных: Загрузите group_log.csv из корзины S3 sprint6 в промежуточную зону.
Настройка схемы базы данных: Создайте таблицы в Vertica для размещения структуры входящих данных.
Загрузка данных в Vertica: Реализуйте DAG в Airflow, который читает файл CSV и загружает его в таблицу group_log.
Создание таблицы связей: Добавьте в схему DWH таблицу связей для соединения данных пользователя и группы.
Сценарии миграции: Напишите SQL-скрипты для миграции данных из промежуточной зоны в таблицу связей, а затем в спутниковую таблицу, фиксирующую истории авторизаций.
Создание и заполнение спутников: Создайте спутниковую таблицу для хранения подробных журналов событий.
 - Подготовка CTE для бизнес-запросов: Реализуйте Common Table Expressions (CTE) для оптимального извлечения данных и ответа на бизнес-запросы о вовлеченности пользователей в группы.

Шаг 3: Создание таблиц в STAGING
Создайте структуру таблиц для первичного хранения данных перед их обработкой и переносом в DWH.

Таблица users для данных пользователей.
Таблица groups для данных о группах.
Таблица dialogs для данных о сообщениях и диалогах.
Шаг 4: Создание таблиц в DWH
Создайте таблицы в хранилище данных, которые будут использоваться для долгосрочного хранения и анализа данных.

Хабы:
h_users для пользовательских данных.
h_dialogs для данных о сообщениях.
h_groups для данных о группах.
Связи:
l_user_message для связей между пользователями и сообщениями.
l_admins для связей между администраторами и их группами.
l_groups_dialogs для связей между группами и диалогами.
Спутники:
s_admins, s_user_chatinfo, s_group_name, s_group_private_status, s_dialog_info, s_user_socdem для хранения дополнительных деталей об элементах в хабах.